{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in here\n",
      "Loaded 0 instances across 10000 exercises...\n",
      "Loaded 0 instances across 20000 exercises...\n",
      "Loaded 0 instances across 30000 exercises...\n",
      "Loaded 0 instances across 40000 exercises...\n",
      "Loaded 0 instances across 50000 exercises...\n",
      "Loaded 0 instances across 60000 exercises...\n",
      "Loaded 0 instances across 70000 exercises...\n",
      "Loaded 0 instances across 80000 exercises...\n",
      "Loaded 0 instances across 90000 exercises...\n",
      "Loaded 0 instances across 100000 exercises...\n",
      "Loaded 0 instances across 110000 exercises...\n",
      "Loaded 0 instances across 120000 exercises...\n",
      "Loaded 0 instances across 130000 exercises...\n",
      "Loaded 0 instances across 140000 exercises...\n",
      "Loaded 0 instances across 150000 exercises...\n",
      "Loaded 0 instances across 160000 exercises...\n",
      "Loaded 0 instances across 170000 exercises...\n",
      "Loaded 0 instances across 180000 exercises...\n",
      "Loaded 0 instances across 190000 exercises...\n",
      "Loaded 0 instances across 200000 exercises...\n",
      "Loaded 0 instances across 210000 exercises...\n",
      "Loaded 0 instances across 220000 exercises...\n",
      "Loaded 0 instances across 230000 exercises...\n",
      "Loaded 0 instances across 240000 exercises...\n",
      "Loaded 0 instances across 250000 exercises...\n",
      "Loaded 0 instances across 260000 exercises...\n",
      "Loaded 0 instances across 270000 exercises...\n",
      "Loaded 0 instances across 280000 exercises...\n",
      "Loaded 0 instances across 290000 exercises...\n",
      "Loaded 0 instances across 300000 exercises...\n",
      "Loaded 0 instances across 310000 exercises...\n",
      "Loaded 0 instances across 320000 exercises...\n",
      "Loaded 0 instances across 330000 exercises...\n",
      "Loaded 0 instances across 340000 exercises...\n",
      "Loaded 0 instances across 350000 exercises...\n",
      "Loaded 0 instances across 360000 exercises...\n",
      "Loaded 0 instances across 370000 exercises...\n",
      "Loaded 0 instances across 380000 exercises...\n",
      "Loaded 0 instances across 390000 exercises...\n",
      "Loaded 0 instances across 400000 exercises...\n",
      "Loaded 0 instances across 410000 exercises...\n",
      "Loaded 0 instances across 420000 exercises...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def create_csv(input_path):\n",
    "\n",
    "    training = (\"train\" in input_path)    \n",
    "    columns=['user','countries','days','client','session','format','time','instance_id','token','part_of_speech','dependency_label','dependency_edge_head','correctness']\n",
    "    df=pd.DataFrame(columns=columns)\n",
    "    num_exercises=0\n",
    "    csv_path=input_path+\".csv\"\n",
    "    records=[]\n",
    "    \n",
    "    print(\"in here\")\n",
    "    for line in open(input_path):\n",
    "        line = line.strip()\n",
    "\n",
    "        # If there's nothing in the line, then we're done with the exercise. Print if needed, otherwise continue\n",
    "        if len(line) == 0:\n",
    "            num_exercises += 1\n",
    "            if num_exercises % 10000 == 0:\n",
    "                print('Loaded ' + str(len(df.index)) + ' instances across ' + str(num_exercises) + ' exercises...')\n",
    "                records_dict=dict()\n",
    "                for ind,record in enumerate(records):\n",
    "                    records_dict[ind]=record\n",
    "                df.from_dict(records_dict,orient='index').to_csv(csv_path)\n",
    "\n",
    "        # If the line starts with #, then we're beginning a new exercise\n",
    "        elif line[0] == '#':\n",
    "            list_of_exercise_parameters = line[2:].split()\n",
    "            exercise_properties = dict()\n",
    "            for exercise_parameter in list_of_exercise_parameters:\n",
    "                [key, value] = exercise_parameter.split(':')\n",
    "                if key=='user':\n",
    "                    value=str(value)\n",
    "                if key == 'countries':\n",
    "                    value = value.split('|')[0]  # select the very first country that the user specified\n",
    "#                     if (len(value)>1):\n",
    "#                         print(\"This user has more than one country \"+line)\n",
    "                \n",
    "                elif key == 'days':\n",
    "                    value = float(value)\n",
    "                elif key == 'client':\n",
    "                    value = (1 if value==\"web\" else (2 if value==\"ios\" else 3))\n",
    "                elif key=='session':\n",
    "                    value=(1 if value==\"lesson\" else (2 if value==\"practice\" else 3))\n",
    "                elif key=='format':\n",
    "                    value=(1 if value==\"reverse_translate\" else (2 if value==\"reverse_tap\" else 3))\n",
    "                elif key == 'time':\n",
    "                    if value == 'null' or float(value)<=0:\n",
    "                        value = None\n",
    "                    else:\n",
    "                        assert '.' not in value\n",
    "                        value = int(value)\n",
    "                if value!=None:\n",
    "                    exercise_properties[key] = value\n",
    "\n",
    "        # Otherwise we're parsing a new Instance for the current exercise\n",
    "        else:\n",
    "            instance_properties=dict(exercise_properties)\n",
    "            line = line.split()\n",
    "            if training:\n",
    "                assert len(line) == 7\n",
    "            else:\n",
    "                assert len(line) == 6\n",
    "            assert len(line[0]) == 12\n",
    "\n",
    "            instance_properties['instance_id'] = line[0]\n",
    "            instance_properties['token'] = line[1]\n",
    "            instance_properties['part_of_speech'] = line[2]\n",
    "            # TODO starts\n",
    "            for l in line[3].split('|'):\n",
    "                [key, value] = l.split('=')\n",
    "                if key == 'Person':\n",
    "                    value = int(value)\n",
    "                instance_properties['morphological_features_'+key]=value\n",
    "                \n",
    "            # TODO ends\n",
    "\n",
    "            instance_properties['dependency_label'] = line[4]\n",
    "            instance_properties['dependency_edge_head'] = int(line[5])\n",
    "            if training:\n",
    "                instance_properties['correctness'] = float(line[6])\n",
    "#             df=df.append(instance_properties,ignore_index=True)\n",
    "            records+=[instance_properties]\n",
    "        \n",
    "#         df.to_csv(csv_path)\n",
    "                \n",
    "                \n",
    "create_csv(\"../data/data_es_en/es_en.slam.20171218.train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
